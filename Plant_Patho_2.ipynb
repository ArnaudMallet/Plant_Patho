{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3642 total images.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Test_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Test_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Test_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1816</td>\n",
       "      <td>Test_1816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1817</td>\n",
       "      <td>Test_1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1818</td>\n",
       "      <td>Test_1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1819</td>\n",
       "      <td>Test_1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>Test_1820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id\n",
       "0        Test_0\n",
       "1        Test_1\n",
       "2        Test_2\n",
       "3        Test_3\n",
       "4        Test_4\n",
       "...         ...\n",
       "1816  Test_1816\n",
       "1817  Test_1817\n",
       "1818  Test_1818\n",
       "1819  Test_1819\n",
       "1820  Test_1820\n",
       "\n",
       "[1821 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verification of the number of Images \n",
    "\n",
    "# load filenames for human and dog images\n",
    "dataset = np.array(glob(data_dir+\"images/*\"))\n",
    "# print number of images in each dataset\n",
    "print('There are %d total images.' % len(dataset))\n",
    "\n",
    "sample_csv = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "test_csv = pd.read_csv(data_dir + 'test.csv')\n",
    "train_csv = pd.read_csv(data_dir + 'train.csv')\n",
    "\n",
    "test_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, id_col, target_col, root_dir, sufix=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file   (string):             Path to the csv file with annotations.\n",
    "            root_dir   (string):             Directory with all the images.\n",
    "            id_col     (string):             csv id column name.\n",
    "            target_col (string):             csv target column name.\n",
    "            sufix      (string, optional):   Optional sufix for samples.\n",
    "            transform  (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data      = pd.read_csv(csv_file)\n",
    "        self.id        = id_col\n",
    "        self.target    = target_col\n",
    "        self.root      = root_dir\n",
    "        self.sufix     = sufix\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the image name at the different idx\n",
    "        img_name = self.data.loc[idx, self.id]\n",
    "        \n",
    "        # if there is not sufic, nothing happened. in this case sufix is '.jpg'\n",
    "        if self.sufix is not None:\n",
    "            img_name = img_name + self.sufix\n",
    "        \n",
    "        # it opens the image of the img_name at the specific idx\n",
    "        image = Image.open(os.path.join(self.root, img_name))\n",
    "        \n",
    "        # if there is not transform nothing happens, here we defined below two transforms for train and for test\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # define the label based on the idx\n",
    "        label = self.data.iloc[idx, 1:5].values.astype('int64')\n",
    "        label = np.argwhere(label ==1)\n",
    "        label = label.item(0)\n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0 0 1 0]\n",
      "<class 'numpy.ndarray'>\n",
      "[[2]]\n",
      "2\n",
      "<class 'int'>\n",
      "tensor([2])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[2]])\n"
     ]
    }
   ],
   "source": [
    "plok = pd.read_csv(data_dir+'train.csv').iloc[3, 1:5].values.astype('int64')\n",
    "print(type(plok))\n",
    "print(plok)\n",
    "\n",
    "plok2 = np.argwhere(plok ==1)\n",
    "print(type(plok2))\n",
    "print(plok2)\n",
    "inter = plok2.item(0)\n",
    "print(inter)\n",
    "print(type(inter))\n",
    "inter_2 = torch.tensor([inter])\n",
    "print(inter_2)\n",
    "print(type(inter_2))\n",
    "lable_plok = torch.from_numpy(plok2)\n",
    "print(lable_plok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row: {} torch.Size([3, 224, 224])\n",
      "image size at the first row: torch.Size([3, 224, 224])\n",
      "Lab at the first row: {} <class 'torch.Tensor'>\n",
      "lab format at the first row: 3\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size = {} torch.Size([4, 3, 224, 224])\n",
      "labels type on batch size = <class 'torch.Tensor'>\n",
      "labels shape on batch size = {} torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'id_col':     'image_id',  \n",
    "    'target_col': ['healthy', 'multiple_diseases', 'rust', 'scab'],\n",
    "    'sufix':      '.jpg',\n",
    "    'transform':  data_transforms['train']\n",
    "}\n",
    "\n",
    "train_dataset = CustomDataset(csv_file=data_dir+'train.csv', root_dir=data_dir+'images', **params)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print('TRAINING')\n",
    "img, lab = train_dataset.__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: {}', img.shape)\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('Lab at the first row: {}', type(lab))\n",
    "print('lab format at the first row: {}'.format(lab))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(train_loader)\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = {}', images.shape)\n",
    "print('labels type on batch size = {}'.format(type(labels)))\n",
    "print('labels shape on batch size = {}', labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=50176, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        # CL sees 224 x 224 x 3 image tensor\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # CL sees 112 x 112 x 16\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # CL sees 56 x 56 x 32\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layer (64 * 28 * 28 -> 500)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 500)\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, 4)\n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior       \n",
    "        x = self.pool(F.relu(self.conv1(x)))      \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))       \n",
    "        # flatten image input\n",
    "        x = x.view(-1, 64 * 28 * 28)\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # add dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # output layer layer, with sigmoid activation function\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "model_patho = Net()\n",
    "model_patho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer = optim.SGD(model_patho.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders):\n",
    "\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            #target = target.squeeze(-1)\n",
    "            #print(target.shape)\n",
    "            \n",
    "            #print('\\nIndex\\n', idx) \n",
    "            #print('\\n DATA \\n', data)\n",
    "            #print('n', data.shape)\n",
    "            #print('\\n OUTPUT \\n', output)\n",
    "            #print('n', output.shape)\n",
    "            #print('\\n TARGET \\n', target)\n",
    "            #print('n', target.shape)\n",
    "        \n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            #update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders.sampler)\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            torch.save(model_patho.state_dict(), 'model_patho.pt')\n",
    "            ))\n",
    "            \n",
    "    # return trained model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.269125\n",
      "Epoch: 2 \tTraining Loss: 1.266718\n",
      "Epoch: 3 \tTraining Loss: 1.265570\n",
      "Epoch: 4 \tTraining Loss: 1.265643\n",
      "Epoch: 5 \tTraining Loss: 1.265025\n",
      "Epoch: 6 \tTraining Loss: 1.264721\n",
      "Epoch: 7 \tTraining Loss: 1.264663\n",
      "Epoch: 8 \tTraining Loss: 1.264622\n",
      "Epoch: 9 \tTraining Loss: 1.264276\n",
      "Epoch: 10 \tTraining Loss: 1.264425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res = train(10, train_loader, model_patho, optimizer, criterion)\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_res.load_state_dict(torch.load('model_patho.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = Image.open(open(\"images/Test_3.jpg\", 'rb'))\n",
    "\n",
    "test_img = data_transforms['test'](test_img)\n",
    "\n",
    "test_img.shape\n",
    "\n",
    "#res = model_res(test_img)\n",
    "\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET TEST\n",
      "image at the first row: {} torch.Size([3, 224, 224])\n",
      "image size at the first row: torch.Size([3, 224, 224])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size = {} torch.Size([4, 3, 224, 224])\n",
      "labels type on batch size = <class 'torch.Tensor'>\n",
      "labels shape on batch size = {} torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset_test(Dataset):\n",
    "    def __init__(self, csv_file, id_col, target_col, root_dir, sufix=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file   (string):             Path to the csv file with annotations.\n",
    "            root_dir   (string):             Directory with all the images.\n",
    "            id_col     (string):             csv id column name.\n",
    "            target_col (string):             csv target column name.\n",
    "            sufix      (string, optional):   Optional sufix for samples.\n",
    "            transform  (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data      = pd.read_csv(csv_file)\n",
    "        self.id        = id_col\n",
    "        self.target    = target_col\n",
    "        self.root      = root_dir\n",
    "        self.sufix     = sufix\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the image name at the different idx\n",
    "        img_name = self.data.loc[idx, self.id]\n",
    "        \n",
    "        # if there is not sufic, nothing happened. in this case sufix is '.jpg'\n",
    "        if self.sufix is not None:\n",
    "            img_name = img_name + self.sufix\n",
    "        \n",
    "        # it opens the image of the img_name at the specific idx\n",
    "        image = Image.open(os.path.join(self.root, img_name))\n",
    "        \n",
    "        # if there is not transform nothing happens, here we defined below two transforms for train and for test\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "data_transforms_test = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'id_col':     'image_id',  \n",
    "    'target_col': ['healthy', 'multiple_diseases', 'rust', 'scab'],\n",
    "    'sufix':      '.jpg',\n",
    "    'transform':  data_transforms['test']\n",
    "}\n",
    "\n",
    "test_dataset = CustomDataset_test(csv_file=data_dir+'test.csv', root_dir=data_dir+'images', **params)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print('TRAINING')\n",
    "img_test = test_dataset.__getitem__(0)\n",
    "\n",
    "print('DATASET TEST')\n",
    "print('image at the first row: {}', img_test.shape)\n",
    "print('image size at the first row: {}'.format(img_test.size()))\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "test_iter = iter(test_loader)\n",
    "print(type(test_iter))\n",
    "\n",
    "images_test, labels_test = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images_test)))\n",
    "print('images shape on batch size = {}', images_test.shape)\n",
    "print('labels type on batch size = {}'.format(type(labels_test)))\n",
    "print('labels shape on batch size = {}', labels_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imshow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-360e9d7e30d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# print images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'imshow' is not defined"
     ]
    }
   ],
   "source": [
    "classes = ('healthy', 'multiple_diseases', 'rust', 'scab')\n",
    "\n",
    "dataiter_test = iter(test_loader)\n",
    "images_test = dataiter_test.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amallet\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\functional.py:1350: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "model_test = Net()\n",
    "model_test.load_state_dict(torch.load('model_patho.pt'))\n",
    "\n",
    "outputs_test = model_test(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:   rust  rust  rust  rust\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs_test, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Test_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Test_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Test_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Test_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Test_4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  healthy  multiple_diseases  rust  scab\n",
       "0   Test_0        0                  0     0     0\n",
       "1   Test_1        0                  0     0     0\n",
       "2   Test_2        0                  0     0     0\n",
       "3   Test_3        0                  0     0     0\n",
       "4   Test_4        0                  0     0     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv(data_dir + 'sample_submission.csv')\n",
    "submission_df.iloc[:, 1:] = 0\n",
    "\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = []\n",
    "for batch_idx, data in enumerate(test_loader):\n",
    "    #print(batch_idx)\n",
    "    output = model_test(data)\n",
    "    #print(output)\n",
    "    #output = output.cpu().detach().numpy()\n",
    "    #print(output)\n",
    "    #output = np.argmax(output)\n",
    "    #print(output)\n",
    "    submission.append(output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy = []\n",
    "multiple_disease = []\n",
    "rust = []\n",
    "scab = []\n",
    "for i in tqdm(range(len(submission))):\n",
    "    healthy.append(submission[i][0][0])\n",
    "    multiple_disease.append(submission[i][0][1])\n",
    "    rust.append(submission[i][0][2])\n",
    "    scab.append(submission[i][0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
